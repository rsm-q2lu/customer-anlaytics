{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import LabelEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Fill missing values with 0\n",
    "df.LotFrontage = df.LotFrontage.fillna(0)\n",
    "\n",
    "# Create a boolean mask for categorical columns\n",
    "categorical_mask = (df.dtypes == object)\n",
    "\n",
    "# Get list of categorical column names\n",
    "categorical_columns = df.columns[categorical_mask].tolist()\n",
    "categorical_columns=['MSZoning', 'PavedDrive', 'Neighborhood', 'BldgType', 'HouseStyle']\n",
    "\n",
    "# Print the head of the categorical columns\n",
    "print(df[categorical_columns].head())\n",
    "\n",
    "# Create LabelEncoder object: le\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Apply LabelEncoder to categorical columns\n",
    "df[categorical_columns] = df[categorical_columns].apply(lambda x: le.fit_transform(x))\n",
    "\n",
    "# Print the head of the LabelEncoded categorical columns\n",
    "print(df[categorical_columns].head())\n",
    "\n",
    "# Import necessary modules\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Fill LotFrontage missing values with 0\n",
    "X.LotFrontage = X.LotFrontage.fillna(0)\n",
    "\n",
    "# Setup the pipeline steps: steps\n",
    "steps = [(\"ohe_onestep\", DictVectorizer(sparse=False)),\n",
    "         (\"xgb_model\", xgb.XGBRegressor())]\n",
    "\n",
    "# Create the pipeline: xgb_pipeline\n",
    "xgb_pipeline = Pipeline(steps)\n",
    "\n",
    "# Fit the pipeline\n",
    "xgb_pipeline.fit(X.to_dict(\"records\"),y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_profit\n",
    "<dbl>\n",
    "expected_ROME\n",
    "<dbl>\n",
    "auc\n",
    "<dbl>\n",
    "model\n",
    "<chr>\n",
    "38172.12\t2.04\t0.7660188\tprofessor_model_profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create arrays for the features and the target: X, y\n",
    "X, y = churn_data.iloc[:,:-1], churn_data.iloc[:,-1]\n",
    "\n",
    "# Create the DMatrix from X and y: churn_dmatrix\n",
    "churn_dmatrix = xgb.DMatrix(data=X, label=y)\n",
    "\n",
    "# Create the parameter dictionary: params\n",
    "params = {\"objective\":\"reg:logistic\", \"max_depth\":3}\n",
    "\n",
    "# Perform cross_validation: cv_results\n",
    "cv_results = xgb.cv(dtrain=churn_dmatrix, params=params, \n",
    "                  nfold=3, num_boost_round=5, \n",
    "                  metrics=\"auc\", as_pandas=True, seed=123)\n",
    "\n",
    "# Print cv_results\n",
    "print(cv_results)\n",
    "\n",
    "# Print the AUC\n",
    "print((cv_results[\"test-auc-mean\"]).iloc[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the parameter grid: gbm_param_grid\n",
    "gbm_param_grid = {\n",
    "    'colsample_bytree': [0.3, 0.7],\n",
    "    'n_estimators': [50],\n",
    "    'max_depth': [2, 5]\n",
    "}\n",
    "\n",
    "# Instantiate the regressor: gbm\n",
    "gbm = xgb.XGBRegressor()\n",
    "\n",
    "# Perform grid search: grid_mse\n",
    "grid_mse = GridSearchCV(param_grid=gbm_param_grid,estimator=gbm,scoring=\"neg_mean_squared_error\",cv=4,verbose=1)\n",
    "\n",
    "\n",
    "# Fit grid_mse to the data\n",
    "grid_mse.fit(X,y)\n",
    "\n",
    "# Print the best parameters and lowest RMSE\n",
    "print(\"Best parameters found: \", grid_mse.best_params_)\n",
    "print(\"Lowest RMSE found: \", np.sqrt(np.abs(grid_mse.best_score_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../intuit75k_withstate.csv')\n",
    "data['label']=1\n",
    "data.loc[data.res1 == 'No','label'] = 0\n",
    "\n",
    "categorical_columns=['zip_state','sex']\n",
    "othercol=['numords','last','dollars','sincepurch','bizflag','owntaxprod','version1','upgraded','training']\n",
    "keep=categorical_columns+othercol+['label']\n",
    "combind_data=data.loc[:,keep]\n",
    "combind_data[categorical_columns] = combind_data[categorical_columns].apply(lambda x: LabelEncoder().fit_transform(x))\n",
    "X_train=combind_data.loc[combind_data.training==1].drop(columns='label').drop(columns='training')\n",
    "y_train=combind_data.loc[combind_data.training==1].label\n",
    "X_test=combind_data.loc[combind_data.training==0].drop(columns='label').drop(columns='training')\n",
    "y_test=combind_data.loc[combind_data.training==0].label\n",
    "Xs = np.concatenate((X_train, X_test), axis=0)\n",
    "# Create the DMatrix from X and y: churn_dmatrix\n",
    "train_dmatrix = xgb.DMatrix(data=X_train, label=y_train)\n",
    "\n",
    "# Create the parameter dictionary: params\n",
    "params = {\"objective\":\"reg:logistic\", \"max_depth\":6}\n",
    "\n",
    "# Perform cross_validation: cv_results\n",
    "cv_results = xgb.cv(dtrain=train_dmatrix, params=params, \n",
    "                  nfold=5, num_boost_round=20, \n",
    "                  metrics=\"auc\", as_pandas=True, seed=123,\n",
    "                   early_stopping_rounds=10)\n",
    "\n",
    "# Print cv_results\n",
    "print(cv_results)\n",
    "\n",
    "# Print the AUC\n",
    "print((cv_results[\"test-auc-mean\"]).iloc[-1])\n",
    "\n",
    "test_dmatrix=xgb.DMatrix(data=X_test)\n",
    "\n",
    "#cv_res.shape[0]为最佳迭代次数\n",
    "bst = xgb.train(dtrain=train_dmatrix, params=params,num_boost_round=cv_results.shape[0])\n",
    "y_pre = bst.predict(test_dmatrix)\n",
    "\n",
    "y_pre\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test.values, y_pre)\n",
    "auc_rf = metrics.auc(fpr, tpr)\n",
    "auc_rf\n",
    "\n",
    "#tuning eta\n",
    "eta_vals = [0.001, 0.01, 0.1]\n",
    "best_auc = []\n",
    "\n",
    "for curr_val in eta_vals:\n",
    "\n",
    "    params[\"eta\"] = curr_val\n",
    "    \n",
    "    # Perform cross-validation: cv_results\n",
    "    cv_results = xgb.cv(dtrain=train_dmatrix, params=params, \n",
    "                  nfold=5, num_boost_round=20, \n",
    "                  metrics=\"auc\", as_pandas=True, seed=123,\n",
    "                   early_stopping_rounds=10)\n",
    "    best_auc.append(cv_results[\"test-auc-mean\"].tail().values[-1])\n",
    "    \n",
    "print(pd.DataFrame(list(zip(eta_vals, best_auc)), columns=[\"eta\",\"best_auc\"]))\n",
    "\n",
    "# Create the parameter grid: gbm_param_grid\n",
    "gbm_param_grid = {\n",
    "    'n_estimators': [10,15,20,25], ### how to set n_estimators?\n",
    "    'max_depth': range(2,10)\n",
    "}\n",
    "\n",
    "# Instantiate the regressor: gbm\n",
    "gbm = xgb.XGBClassifier()\n",
    "\n",
    "# Perform grid search: grid_auc\n",
    "randomized_auc = RandomizedSearchCV(\n",
    "    param_distributions=gbm_param_grid,estimator=gbm,scoring=\"roc_auc\",n_iter=50,cv=5,verbose=1\n",
    ")\n",
    "\n",
    "# Fit grid_mse to the data\n",
    "randomized_auc.fit(X_train,y_train)\n",
    "\n",
    "print(\"Best parameters found: \", randomized_auc.best_params_)\n",
    "print(\"higest auc found: \", np.abs(randomized_auc.best_score_))\n",
    "\n",
    "preds =randomized_auc.predict_proba(X_test)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test.values, preds[:, 1])\n",
    "auc_rf = metrics.auc(fpr, tpr)\n",
    "auc_rf\n",
    "xg_cl = xgb.XGBClassifier(objective='binary:logistic', n_estimators=300, max_depth=4)\n",
    "xg_cl.fit(X_train,y_train)\n",
    "preds = xg_cl.predict_proba(X_test)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test.values, preds[:, 1])\n",
    "auc_rf = metrics.auc(fpr, tpr)\n",
    "auc_rf\n",
    "margin=60\n",
    "cost=1.41\n",
    "breakeven_rate=cost/margin\n",
    "\n",
    "testdata=combind_data.loc[combind_data.training==0]\n",
    "testdata['xgboost']=preds[:, 1]\n",
    "testdata['pred_click']=1\n",
    "testdata.loc[testdata['xgboost']<breakeven_rate,'pred_click']=0\n",
    "tp=testdata.loc[testdata.pred_click==1].loc[testdata.label==1]\n",
    "revenue=len(tp)*margin\n",
    "pred_true=sum(testdata.pred_click)\n",
    "totalcost=pred_true*cost\n",
    "profit=revenue-totalcost\n",
    "profit\n",
    "\n",
    "#define a function to be the scoring (predicted profit on the test dataset)\n",
    "from sklearn.metrics import make_scorer\n",
    "def pred_profit(y_true,y_pred):\n",
    "    d = {'label': y_true, 'model': y_pred[:,1]}\n",
    "    df = pd.DataFrame(data=d)\n",
    "    traindata2=df\n",
    "    traindata2['pred_click']=1\n",
    "    traindata2.loc[traindata2['model']/2<breakeven_rate,'pred_click']=0\n",
    "    tp=traindata2.loc[traindata2.pred_click==1].loc[traindata2.label==1]\n",
    "    pred_true=sum(traindata2.pred_click)\n",
    "    pred_true_rate=pred_true/len(traindata2)\n",
    "    send_number=total*pred_true_rate\n",
    "    adj_response_rate=len(tp)/pred_true/2\n",
    "    exp_buyers=adj_response_rate*send_number\n",
    "    totalcost=send_number*cost\n",
    "    exp_profit=exp_buyers*margin-totalcost\n",
    "    return exp_profit\n",
    "\n",
    "score=make_scorer(pred_profit,greater_is_better=True)\n",
    "# Create the parameter grid: gbm_param_grid\n",
    "rf_param_grid = {\n",
    "    'n_estimators': range(100,301,50), ### how to set n_estimators?\n",
    "    'max_depth': range(2,10)\n",
    "}\n",
    "\n",
    "# Instantiate the regressor: gbm\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "# Perform grid search: grid_auc\n",
    "randomized_clf = RandomizedSearchCV(\n",
    "    param_distributions=rf_param_grid,estimator=clf,scoring=score,n_iter=50,cv=5,verbose=1\n",
    ")\n",
    "\n",
    "# Fit grid_mse to the data\n",
    "randomized_clf.fit(X_train,y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
